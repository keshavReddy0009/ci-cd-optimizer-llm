name: LLM CI/CD Optimizer

on:
  push:
    paths:
      - ".github/workflows/*.yml"
  workflow_dispatch:

jobs:
  analyze-pipeline:
    runs-on: ubuntu-latest

    # Needed so the job can read models via GitHub Models
    # and read your repo contents.
    permissions:
      contents: read
      models: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Read ALL workflow files (all .yml in .github/workflows except this optimizer itself)
      - name: Load workflow YAMLs
        id: read_yaml
        run: |
          set -e

          # List all workflow files except llm-optimizer.yml
          FILES=$(ls .github/workflows/*.yml | grep -v "llm-optimizer.yml" || true)

          if [[ -z "$FILES" ]]; then
            echo "No other workflow files found to analyze."
            echo "content=" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "Analyzing the following workflow files:"
          echo "$FILES"

          COMBINED_CONTENT=""

          # Concatenate content of all files with clear separators
          for f in $FILES; do
            BASENAME=$(basename "$f")
            COMBINED_CONTENT+=$'### FILE: '"$BASENAME"$'\n'
            COMBINED_CONTENT+="$(cat "$f")"
            COMBINED_CONTENT+=$'\n\n'
          done

          # Escape for GitHub Actions output
          CONTENT="${COMBINED_CONTENT//'%'/'%25'}"
          CONTENT="${CONTENT//$'\n'/'%0A'}"
          CONTENT="${CONTENT//$'\r'/'%0D'}"

          echo "content=$CONTENT" >> "$GITHUB_OUTPUT"

      # Call GitHub Models via the official AI Inference action
      - name: Analyze CI/CD YAML with LLM
        id: inference
        uses: actions/ai-inference@v1
        with:
          model: openai/gpt-4o-mini
          prompt: |
            You are a CI/CD optimization assistant.

            Below are one or more GitHub Actions workflow YAML files.
            Each file is separated by a line starting with:
            '### FILE: <filename>.yml'

            For EACH FILE, analyze and suggest improvements for:
            - Redundant jobs or steps
            - Missing cache opportunities
            - Security issues (permissions, secrets usage)
            - Cost inefficiencies (long-running or unnecessary jobs)
            - Performance improvements (parallelism, matrix, etc.)

            Return your answer as JSON of this form:
            {
              "files": [
                {
                  "file": "name.yml",
                  "performance": [],
                  "security": [],
                  "cost": [],
                  "other": []
                }
              ]
            }

            --- BEGIN WORKFLOW FILES ---
            ${{ steps.read_yaml.outputs.content }}
            --- END WORKFLOW FILES ---

      - name: Show AI suggestions
        run: |
          echo "LLM response:"
          cat << 'END_LLM_OUTPUT'
          ${{ steps.inference.outputs.response }}
          END_LLM_OUTPUT
